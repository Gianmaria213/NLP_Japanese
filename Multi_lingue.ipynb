{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    }
   ],
   "source": [
    "# Python 3.10\n",
    "\n",
    "import pandas as pd\n",
    "import keras\n",
    "import keras_nlp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import tensorflow_text\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gianmariafredacivico\\.conda\\envs\\Kaggle\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creo gli embedding multi lingue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = hub.load(\"https://www.kaggle.com/models/google/universal-sentence-encoder/frameworks/TensorFlow2/variations/multilingual/versions/2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_df = pd.read_csv('data/eng_df.csv', low_memory=False, index_col=[0])\n",
    "jap_df = pd.read_csv('data/jap_df.csv', low_memory=False, index_col=[0])\n",
    "\n",
    "eng_df = eng_df.drop_duplicates()\n",
    "jap_df = jap_df.drop_duplicates()\n",
    "\n",
    "eng_df = eng_df[eng_df.words.apply(len) > 0]\n",
    "jap_df = jap_df[jap_df.words.apply(len) > 0]\n",
    "\n",
    "eng_df = eng_df.dropna(subset='text')\n",
    "jap_df = jap_df.dropna(subset='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 348935/348935 [2:39:12<00:00, 36.53it/s]  \n"
     ]
    }
   ],
   "source": [
    "df_full = pd.concat([eng_df, jap_df])\n",
    "\n",
    "df_full['embedded_text'] = df_full.text.progress_apply(lambda x: embed(x))\n",
    "df_full.to_csv('data/dataset_full_embedding.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelli su embedding multilingue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gianmariafredacivico\\AppData\\Local\\Temp\\ipykernel_9600\\2121335445.py:1: DtypeWarning: Columns (3,4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_full = pd.read_csv('data/dataset_full_embedding.csv', index_col=[0])\n"
     ]
    }
   ],
   "source": [
    "df_full = pd.read_csv('data/dataset_full_embedding.csv', index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 348935/348935 [01:02<00:00, 5607.23it/s]\n"
     ]
    }
   ],
   "source": [
    "X = df_full['embedded_text'].progress_apply(lambda x: [float(num) for num in x.split(\"[[\")[1].split(\"]]\")[0].split()]).values\n",
    "y = df_full['source'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smote esegue il resampling bilanciando le classi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "X_resampled, y_resampled = smote.fit_resample(np.array([i for i in X]), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/preprocessing/multi/smote.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib \n",
    "\n",
    "\n",
    "joblib.dump(smote, 'models/preprocessing/multi/smote.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di campioni per classe dopo l'applicazione di SMOTE:\n",
      "{'Mainichi Shimbun': 44656, 'The Japan Times': 44656, 'asahi.com': 44656, 'chunichi.co.jp': 44656, 'hokkaido-np.co.jp': 44656, 'isenp.co.jp': 44656, 'iwate-np.co.jp': 44656, 'kobe-np.co.jp': 44656, 'kyoto-np.co.jp': 44656, 'mainichi.jp': 44656, 'nikkansports.com': 44656, 'nikkei.com': 44656, 'nishinippon.co.jp': 44656, 'nnn.co.jp': 44656, 'oita-press.co.jp': 44656, 'sankei.jp.msn.com': 44656, 'sanspo.com': 44656, 'shimotsuke.co.jp': 44656, 'tokachi.co.jp': 44656, 'tokyo-np.co.jp': 44656, 'tomamin.co.jp': 44656, 'yamagata-np.jp': 44656, 'yomiuri.co.jp': 44656}\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(y_resampled, return_counts=True)\n",
    "class_counts = dict(zip(unique, counts))\n",
    "print(\"Numero di campioni per classe dopo l'applicazione di SMOTE:\")\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def mkdir(folder_path):\n",
    "\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "        print(f\"Cartella '{folder_path}' creata con successo.\")\n",
    "    else:\n",
    "        print(f\"La cartella '{folder_path}' esiste già.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cartella 'models/preprocessing/multi' esiste già.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models/preprocessing/multi/label_encoder.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mkdir('models/preprocessing/multi')\n",
    "\n",
    "joblib.dump(label_encoder, 'models/preprocessing/multi/label_encoder.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(821670, 512) (821670,) (205418, 512) (205418,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cartella 'models/multi/' esiste già.\n",
      "starting\n",
      "Fitting xgboost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gianmariafredacivico\\.conda\\envs\\Kaggle\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:28:11] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, path):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    labels = sorted(set(y_true))\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted labels')\n",
    "    plt.ylabel('True labels')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.savefig(path)\n",
    "    plt.close()\n",
    "\n",
    "def evaluate_model(y_true, y_pred, model_name, metrics_path):\n",
    "    report = classification_report(y_true, y_pred, output_dict=True)\n",
    "    df_report = pd.DataFrame(report).transpose()\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    with open(metrics_path, 'a') as file:\n",
    "        file.write(f\"Metrics for {model_name}:\\n\\n\")\n",
    "        file.write(f\"Accuracy: {accuracy:.4f}\\n\\n\")\n",
    "        file.write(\"Classification Report:\\n\")\n",
    "        file.write(df_report.to_string())\n",
    "        file.write(\"\\n\\n\")\n",
    "\n",
    "# Provo due modelli (troppo tempo)\n",
    "models = {\n",
    "    # \"random_forest\": RandomForestClassifier(),\n",
    "    \"xgboost\": XGBClassifier(),\n",
    "}\n",
    "\n",
    "mkdir('models/multi/')\n",
    "\n",
    "print('starting')\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Fitting {model_name}...\")\n",
    "\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    plot_confusion_matrix(y_test, y_pred, f\"models/multi/{model_name}_confusion_matrix.png\")\n",
    "    \n",
    "    evaluate_model(y_test, y_pred, model_name, f\"models/multi/models_metrics.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
